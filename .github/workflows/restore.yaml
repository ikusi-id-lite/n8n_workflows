name: n8n Import Workflows (Optimized arc-runner-set)

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Selecciona el modo de importaci√≥n'
        required: true
        default: 'single'
        type: choice
        options:
          - single
          - all
      file_name:
        description: 'Archivo (ej: mi-flujo-YH8YLjPiXhZj70X2.json)'
        required: false
        default: ''

jobs:
  import-n8n:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install requests

      - name: Run Import Script
        env:
          N8N_API_KEY: ${{ secrets.N8N_API_KEY }}
          N8N_BASE_URL: 'https://process.waysolutions.co/api/v1'
          IMPORT_MODE: ${{ github.event.inputs.mode }}
          FILE_NAME: ${{ github.event.inputs.file_name }}
        run: |
          python << 'EOF'
          import os
          import json
          import requests
          import glob
          import re
          import sys

          api_key = os.getenv('N8N_API_KEY', '').strip()
          base_url = os.getenv('N8N_BASE_URL', '').strip().rstrip('/')
          mode = os.getenv('IMPORT_MODE')
          target_file = os.getenv('FILE_NAME')

          headers = {
              "X-N8N-API-KEY": api_key,
              "Content-Type": "application/json"
          }

          def clean_for_api(data):
              """
              Mantenemos solo lo estrictamente necesario.
              Eliminamos 'active' porque la API lo marca como read-only.
              """
              payload = {}
              payload['name'] = data.get('name', 'Restored Workflow')
              payload['nodes'] = data.get('nodes', [])
              payload['connections'] = data.get('connections', {})
              
              if 'settings' in data:
                  payload['settings'] = data['settings']
              if 'staticData' in data:
                  payload['staticData'] = data['staticData']
                  
              return payload

          def extract_id(filename):
              match = re.search(r'-([a-zA-Z0-9]+)\.json$', filename)
              return match.group(1) if match else None

          def upload_workflow(file_path):
              workflow_id = extract_id(file_path)
              if not workflow_id: return

              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      content = json.load(f)

                  raw_data = content[0] if isinstance(content, list) else content
                  clean_payload = clean_for_api(raw_data)

                  url = f"{base_url}/workflows/{workflow_id}"
                  check = requests.get(url, headers=headers)

                  if check.status_code == 200:
                      print(f"üîÑ Actualizando ID: {workflow_id}")
                      res = requests.put(url, headers=headers, json=clean_payload)
                  else:
                      print(f"üÜï Creando nuevo: {workflow_id}")
                      res = requests.post(f"{base_url}/workflows", headers=headers, json=clean_payload)
                  
                  if res.status_code in [200, 201]:
                      print(f"‚úÖ √âxito: {file_path}")
                  else:
                      print(f"‚ùå Error API ({res.status_code}): {res.text}")

              except Exception as e:
                  print(f"üí• Error: {str(e)}")

          if mode == 'single':
              upload_workflow(target_file)
          else:
              for f in glob.glob("*.json"):
                  upload_workflow(f)
          EOF